<!-- RadarGun 3.0 benchmark -->
<benchmark xmlns="urn:radargun:benchmark:3.0">

   <!-- Specifies where should the master open socket  -->
   <master bindAddress="${master.address:127.0.0.1}" port="${master.port:2103}"/>

   <!-- List of cluster configurations where the benchmark should run-->
   <clusters>
      <cluster size="2" />
   </clusters>

   <!-- List of configurations of the services -->
   <configurations>
      <config name="Infinispan 6.0 - distributed">
         <setup plugin="infinispan60">
            <embedded xmlns="urn:radargun:plugins:infinispan60:3.0" file="dist-sync.xml" />
         </setup>
      </config>
   </configurations>

   <!-- Sequence of stages executed on the cluster -->
   <rg:scenario xmlns:rg="urn:radargun:benchmark:3.0" xmlns="urn:radargun:stages:core:3.0">
      <!-- Start services on all nodes -->
      <service-start />
      <!-- Begin monitoring of CPU, memory usage and GC -->
      <jvm-monitor-start />

      <!-- Preload the cache with data -->
      <cache-load num-entries="5000"/>

      <!-- As the test is called 'warmup', performance statistics won't be reported -->
      <basic-operations-test-setup test-name="warmup"
                                   ramp-up-min-steady-period="${warmup.duration:1m}"
                                   num-entries="5000">
         <!-- The test will execute a cache.get() request every 2 ms and put request every 8 ms -->
         <get interval="2" invocations="1"/>
         <put interval="10" invocations="1"/>
      </basic-operations-test-setup>
      <test test-name="warmup" duration="${warmup.duration:1m}" />

      <!-- Remove all data from the default cache -->
      <cache-clear />
      <!-- Again, preload the cache with data -->
      <cache-load num-entries="10000"/>

      <!-- We will scale the load up here, from 1000 gets/s to 3000 gets/s and from 250 puts/s to 750 puts/s -->
      <repeat from="1" to="3">
         <!-- In this stage we'll set goals for test execution -->
         <basic-operations-test-setup test-name="stress-test"
                                      ramp-up-min-steady-period="${test.duration:1m}"
                                      num-entries="10000">
            <get interval="2" invocations="${repeat.counter}"/>
            <put interval="10" invocations="${repeat.counter}"/>
         </basic-operations-test-setup>
         <!-- Here we run the test according to previous setting, in so-called steady state.
              We set finish="false" because the test will continue in next loop. -->
         <test test-name="stress-test" amend-test="true" finish="false"
               duration="${test.duration:1m}">
            <!-- Terminate the test when we can't achieve 95% of expected throughput,
                 or if the mean time is 1 ms or more  -->
            <repeat-condition>
               <all>
                  <throughput-net on="BasicOperations.Put" over="#{ ${repeat.counter} * 100 * 95 / 100 }"/>
                  <mean on="BasicOperations.Put" below="1 ms" />
               </all>
            </repeat-condition>
         </test>
      </repeat>

      <!-- Stop JVM monitoring -->
      <jvm-monitor-stop />
   </rg:scenario>

   <!-- How the statistics are reported -->
   <reports>
      <!-- Produce CSV statistics report -->
      <reporter type="csv" />
      <!-- Produce HTML statistics report -->
      <reporter type="html" />
   </reports>

</benchmark>
